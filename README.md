## Описание выполненной работы

В рамках выполненного задания, я разработала рекомендательную систему для социальной сети студентов Karpov Courses. Эта система генерирует персонализированные ленты для пользователей, учитывая их индивидуальные характеристики, прошлую активность и содержимое постов.

### 1. Сбор данных
В качестве исходных данных использовались таблицы, подготовленные командой курса, которые включают информацию о пользователях, их профилях, сообществах, постах и активности пользователей (например, лайки и просмотры постов).

### 2. Понимание предпочтений пользователей
Для каждого пользователя система анализирует его прошлую активность (например, какие посты он лайкал, какие сообщества он посещал) и использует эти данные для формирования рекомендаций. Это позволяет учитывать интересы пользователя и повышать релевантность постов в его ленте.

### 3. Разработка модели рекомендаций
Я построила систему рекомендаций, которая учитывает следующие параметры:
- **Профиль пользователя**: данные о пользователе (например, возраст, интересы, активность) влияют на то, какие посты ему будут рекомендованы.
- **Активность пользователя**: просмотренные посты, поставленные лайки, участвующие сообщества — все это используется для вычисления предпочтений.
- **Содержание постов**: каждый пост также имеет определенные характеристики (например, теги, сообщества), которые используются для сопоставления с интересами пользователей.

### 4. Реализация функционала
Я реализовала сервис, который для каждого пользователя динамически генерирует ленту с постами, которые имеют наибольшую вероятность понравиться на основе вышеупомянутых факторов. Система обновляет ленту в реальном времени, обеспечивая актуальные рекомендации.

### 5. Технологическая реализация
Для хранения данных использовалась PostgreSQL база данных, где хранятся все данные о пользователях, постах и их активности. Я применяла методы извлечения, обработки и анализа данных для построения эффективной системы рекомендаций.

### 6. Персонализация ленты
Система подбирает посты, которые не являются случайными, а точечно ориентированы на предпочтения конкретного пользователя, обеспечивая высокую релевантность рекомендаций и улучшая пользовательский опыт на платформе.

### Ход работы

#### 1. **Анализ трех таблиц**
Для начала я проанализировала три основные таблицы базы данных:
- **Таблица пользователей**: Содержит информацию о каждом пользователе (например, имя, возраст, интересы).
- **Таблица постов**: Содержит информацию о постах, опубликованных в сообществе, включая текст поста, метки и другие характеристики.
- **Таблица активности пользователей**: Включает данные о действиях пользователей (например, лайки, просмотры постов, участие в сообществах).

#### 2. **Извлечение новых признаков**
Для улучшения модели были извлечены новые признаки с помощью различных методов:
- **TF-IDF**: Использована для извлечения признаков из текста постов и выделения значимых слов, которые могут быть полезными для рекомендаций.
- **One-Hot Encoding (OHE)**: Применен для кодирования категориальных признаков, таких как теги и категории сообществ, чтобы модель могла учитывать их в обучении.
- **Mean Target Encoding (MTE)**: Применен для кодирования категориальных признаков с помощью среднего целевого значения, что помогает улучшить точность модели.
- **Label Encoding**: Использовано для кодирования категориальных признаков, таких как идентификаторы пользователей и постов, в числовую форму.

#### 3. **Использование валидации, стандартизации и балансировки классов**
- **Валидация**: Для оценки модели использовалась кросс-валидация, что позволяет уменьшить вероятность переобучения и повысить общую точность модели.
- **Стандартизация**: Для улучшения результатов обучения была применена стандартизация числовых признаков, что позволяет моделям лучше работать с различными шкалами данных.
- **Балансировка классов**: Для улучшения работы с несбалансированными данными (например, когда некоторые посты получают намного больше лайков, чем другие) были использованы методы балансировки классов, такие как oversampling и undersampling.

#### 4. **Обучение моделей**
Я использовала несколько моделей машинного обучения для построения рекомендательной системы:
- **CatBoost**: Модель градиентного бустинга, хорошо работающая с категориальными признаками, использовалась для предсказания вероятности того, что пользователь поставит лайк тому или иному посту.
- **Random Forest**: Метод случайного леса был использован для классификации и построения предсказаний на основе различных признаков. Это оказалась лучшая модель для данной задачи, показавшая отличные результаты по точности рекомендаций.
- **Logistic Regression**: Логистическая регрессия использовалась для бинарной классификации, чтобы предсказать, поставит ли пользователь лайк на пост.
- **XGBoost**: Еще один мощный алгоритм градиентного бустинга, примененный для оптимизации производительности модели.

#### 5. **Оценка моделей с использованием HitRate@5**
Для оценки качества работы рекомендательной системы использовалась метрика **HitRate@5**. Эта метрика измеряет, сколько раз из 5 рекомендованных постов хотя бы один пост будет выбран пользователем (например, получит лайк). Такая метрика помогает оценить точность рекомендаций в условиях реального применения, где важно не просто рекомендовать лучший пост, а предложить несколько постов, среди которых пользователь будет заинтересован в одном или нескольких.

По итогам, лучшая модель для данной задачи — **Random Forest**, которая достигла **HitRate@5 = 0.521**. Это означает, что в 52.1% случаев хотя бы один из пяти рекомендованных постов будет выбран пользователем. 

### Результат
Теперь каждый пользователь социальной сети получает персонализированную ленту, которая состоит из постов, наиболее подходящих для его интересов и предыдущей активности. Это повышает вовлеченность пользователей и улучшает качество их взаимодействия с платформой.
